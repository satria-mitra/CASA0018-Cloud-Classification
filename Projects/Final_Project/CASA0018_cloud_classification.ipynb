{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satria-mitra/CASA0018-Cloud-Classification/blob/main/Projects/Final_Project/CASA0018_cloud_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGyTseD59OSm"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satria-mitra/CASA0018-Cloud-Classification/blob/main/Projects/Final%20Project/CASA0018_cloud_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instruction**\n",
        "\n",
        "This project, Cloud classification, is part of CASA0018 Deep Learning project. The dataset is available to download from the link below. However, some images are taken by myself or from publis image repository such as Flickr. Follow the steps on this tutorial to see the result. One may have different result since the datasets are not identic.\n",
        "\n",
        "\n",
        "1.   Download Cirrus Cumulus Stratus Nimbus (CCSN) Database\n",
        "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD&version=2.0\n",
        "\n",
        "2.   Download Howard-Cloud-X\n",
        "https://www.kaggle.com/datasets/imbikramsaha/howard-cloudx/code"
      ],
      "metadata": {
        "id": "lMshZUzm9fUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Cleaning**\n",
        "#### Manual checking the image\n",
        "\n",
        "While CCSN datasets has 10 cloud types + 1 contrail, Howard-Cloud-X only has 10 cloud types without contrail.\n",
        "\n",
        "First, lets see how many pictures for each type of cloud from the two datasets"
      ],
      "metadata": {
        "id": "MJKlCiJiBwS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDWMHW399OSn"
      },
      "outputs": [],
      "source": [
        "import cv2 #opencv\n",
        "import os\n",
        "import time\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KhsG0Om-5aD",
        "outputId": "60390c31-c75e-4140-f016-3e9987240073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K1isNzn9OSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680c02d1-490f-442e-c348-1fa1fdf5cc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files and directories in ' /content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/CCSN_v2 ' : ['Sc', 'Ns', 'Ci', 'Cu', 'Cs', 'Ct', 'St', 'As', 'Cc', 'Ac', 'Cb']\n"
          ]
        }
      ],
      "source": [
        "CCSN_path = '/content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/CCSN_v2' #Directories of Google Drive\n",
        "\n",
        "os.chdir(CCSN_path) #Go to path\n",
        "os.listdir(CCSN_path) #List out files in the path\n",
        "print(\"Files and directories in '\", CCSN_path, \"' :\", os.listdir(CCSN_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Howard_path = '/content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/Howard-Cloud-X' #Directories of Google Drive\n",
        "os.chdir(Howard_path) #Go to path\n",
        "os.listdir(Howard_path) #List out files in the path\n",
        "print(\"Files and directories in '\", Howard_path, \"' :\", os.listdir(Howard_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCX5vAwBAqN_",
        "outputId": "104b54c2-1f6d-4804-da75-f37ebd41c03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files and directories in ' /content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/Howard-Cloud-X ' : ['Ac', 'As', 'Cc', 'Cs', 'Ci', 'Cb', 'Cu', 'Ns', 'Sc', 'St']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CCSN_dir = os.listdir(CCSN_path)\n",
        "for dir_name in CCSN_dir:\n",
        "    # Create the full path to the directory\n",
        "    dir_path = os.path.join(CCSN_path, dir_name)\n",
        "\n",
        "    # Get a list of files in the directory\n",
        "    files = os.listdir(dir_path)\n",
        "\n",
        "    # Count the number of files\n",
        "    num_files = len(files)\n",
        "\n",
        "    # Print the directory name and the number of files it contains\n",
        "    print(f\"{dir_name}: {num_files} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69cfaVHHB3iU",
        "outputId": "451b5bb3-6afa-41e0-8ab2-db1be2dcc00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sc: 208 files\n",
            "Ns: 162 files\n",
            "Ci: 74 files\n",
            "Cu: 109 files\n",
            "Cs: 58 files\n",
            "Ct: 155 files\n",
            "St: 202 files\n",
            "As: 65 files\n",
            "Cc: 105 files\n",
            "Ac: 118 files\n",
            "Cb: 193 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Howard_dir = os.listdir(Howard_path)\n",
        "for dir_name in Howard_dir:\n",
        "    # Create the full path to the directory\n",
        "    dir_path = os.path.join(Howard_path, dir_name)\n",
        "\n",
        "    # Get a list of files in the directory\n",
        "    files = os.listdir(dir_path)\n",
        "\n",
        "    # Count the number of files\n",
        "    num_files = len(files)\n",
        "\n",
        "    # Print the directory name and the number of files it contains\n",
        "    print(f\"{dir_name}: {num_files} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6-E_EGD_fJq",
        "outputId": "b1abe817-8ece-43c4-dd27-41c211559062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ac: 136 files\n",
            "As: 187 files\n",
            "Cc: 131 files\n",
            "Cs: 129 files\n",
            "Ci: 120 files\n",
            "Cb: 124 files\n",
            "Cu: 188 files\n",
            "Ns: 131 files\n",
            "Sc: 132 files\n",
            "St: 137 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine files from both datasets"
      ],
      "metadata": {
        "id": "--C6A8G-HHaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_path = '/content/datasets'\n",
        "if not os.path.exists(combined_path):\n",
        "    os.makedirs(combined_path)\n",
        "\n",
        "# Function to copy files from source to destination\n",
        "def copy_files(source_path):\n",
        "    for dir_name in os.listdir(source_path):\n",
        "        dir_path = os.path.join(source_path, dir_name)\n",
        "        files = os.listdir(dir_path)\n",
        "        for file in files:\n",
        "            # Define source and destination file paths\n",
        "            src_file_path = os.path.join(dir_path, file)\n",
        "            dst_file_path = os.path.join(combined_path, file)\n",
        "\n",
        "            # Check if file already exists to avoid overwrites\n",
        "            if not os.path.exists(dst_file_path):\n",
        "                shutil.copy(src_file_path, dst_file_path)\n",
        "            else:\n",
        "                # If file exists, rename and copy\n",
        "                base, extension = os.path.splitext(file)\n",
        "                new_name = f\"{base}_duplicate{extension}\"\n",
        "                dst_file_path = os.path.join(combined_path, new_name)\n",
        "                shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "id": "7UGqlTfzJVE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MGKM3qa4JRWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Processing**\n",
        "#### Import Dependancies and modules required"
      ],
      "metadata": {
        "id": "gYW46N579g2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH5_wLSM9OSn"
      },
      "outputs": [],
      "source": [
        "import os #for creating path names and manipulating directories/files in an operating system\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1sYJp1N9OSn",
        "outputId": "d0fa32f9-7454-47bc-adcd-80322698a3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import os #for creating path names and manipulating directories/files in an operating system\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime #for tensorboard and logging\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Data Directory in Google Drive"
      ],
      "metadata": {
        "id": "XU6TAZGj_U5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CCSN Datasets"
      ],
      "metadata": {
        "id": "PblWm3m7AZfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Howard Datasets"
      ],
      "metadata": {
        "id": "HyCaEsVRAgAd"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}