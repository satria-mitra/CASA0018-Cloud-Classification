{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satria-mitra/CASA0018-Cloud-Classification/blob/main/Projects/Final_Project/CASA0018_cloud_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instruction**\n",
        "\n",
        "This project, Cloud classification, is part of CASA0018 Deep Learning project. The dataset is available to download from the link below. However, some images are taken by myself or from publis image repository such as Flickr. Follow the steps on this tutorial to see the result. One may have different result since the datasets are not identic.\n",
        "\n",
        "\n",
        "1.   Download Cirrus Cumulus Stratus Nimbus (CCSN) Database\n",
        "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CADDPD&version=2.0\n",
        "\n",
        "2.   Download Howard-Cloud-X\n",
        "https://www.kaggle.com/datasets/imbikramsaha/howard-cloudx/code"
      ],
      "metadata": {
        "id": "lMshZUzm9fUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Cleaning**\n",
        "#### Manual checking the image\n",
        "\n",
        "While CCSN datasets has 10 cloud types + 1 contrail, Howard-Cloud-X only has 10 cloud types without contrail.\n",
        "\n",
        "First, lets see how many pictures for each type of cloud from the two datasets"
      ],
      "metadata": {
        "id": "MJKlCiJiBwS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rDWMHW399OSn"
      },
      "outputs": [],
      "source": [
        "import cv2 #opencv\n",
        "import os\n",
        "import time\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KhsG0Om-5aD",
        "outputId": "8109f1aa-abb7-4643-ba5d-7bd772afbc1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6K1isNzn9OSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60af1c8e-3b3a-4afc-f97d-a5f30252f42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files and directories in ' /content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/CCSN_v2 ' : ['Sc', 'Ns', 'Ci', 'Cu', 'Cs', 'Ct', 'St', 'As', 'Cc', 'Ac', 'Cb']\n"
          ]
        }
      ],
      "source": [
        "CCSN_path = '/content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/CCSN_v2' #Directories of Google Drive\n",
        "\n",
        "os.chdir(CCSN_path) #Go to path\n",
        "os.listdir(CCSN_path) #List out files in the path\n",
        "print(\"Files and directories in '\", CCSN_path, \"' :\", os.listdir(CCSN_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Howard_path = '/content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/Howard-Cloud-X' #Directories of Google Drive\n",
        "os.chdir(Howard_path) #Go to path\n",
        "os.listdir(Howard_path) #List out files in the path\n",
        "print(\"Files and directories in '\", Howard_path, \"' :\", os.listdir(Howard_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCX5vAwBAqN_",
        "outputId": "014ebbac-1f04-4154-dc85-525f1f925591"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files and directories in ' /content/drive/MyDrive/Kuliah/UCL/Projects/CASA0018-Cloud-Classification/Projects/Final_Project/Datasets/Howard-Cloud-X ' : ['Ac', 'As', 'Cc', 'Cs', 'Ci', 'Cb', 'Cu', 'Ns', 'Sc', 'St']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CCSN_dir = os.listdir(CCSN_path)\n",
        "for dir_name in CCSN_dir:\n",
        "    # Create the full path to the directory\n",
        "    dir_path = os.path.join(CCSN_path, dir_name)\n",
        "\n",
        "    # Get a list of files in the directory\n",
        "    files = os.listdir(dir_path)\n",
        "\n",
        "    # Count the number of files\n",
        "    num_files = len(files)\n",
        "\n",
        "    # Print the directory name and the number of files it contains\n",
        "    print(f\"{dir_name}: {num_files} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69cfaVHHB3iU",
        "outputId": "3a11a7f8-8376-4773-a392-2d36ee7dcf3c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sc: 208 files\n",
            "Ns: 162 files\n",
            "Ci: 74 files\n",
            "Cu: 109 files\n",
            "Cs: 58 files\n",
            "Ct: 155 files\n",
            "St: 202 files\n",
            "As: 65 files\n",
            "Cc: 105 files\n",
            "Ac: 118 files\n",
            "Cb: 193 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Howard_dir = os.listdir(Howard_path)\n",
        "for dir_name in Howard_dir:\n",
        "    # Create the full path to the directory\n",
        "    dir_path = os.path.join(Howard_path, dir_name)\n",
        "\n",
        "    # Get a list of files in the directory\n",
        "    files = os.listdir(dir_path)\n",
        "\n",
        "    # Count the number of files\n",
        "    num_files = len(files)\n",
        "\n",
        "    # Print the directory name and the number of files it contains\n",
        "    print(f\"{dir_name}: {num_files} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6-E_EGD_fJq",
        "outputId": "58ee1b1e-148d-4f7e-ed72-d66a0f0267e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ac: 136 files\n",
            "As: 187 files\n",
            "Cc: 131 files\n",
            "Cs: 129 files\n",
            "Ci: 120 files\n",
            "Cb: 124 files\n",
            "Cu: 188 files\n",
            "Ns: 131 files\n",
            "Sc: 132 files\n",
            "St: 137 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine files from both datasets"
      ],
      "metadata": {
        "id": "--C6A8G-HHaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "combined_path = '/content/combined_datasets'\n",
        "for dir_name in os.listdir(CCSN_path):\n",
        "    combined_subdir = os.path.join(combined_path, dir_name)\n",
        "    if not os.path.exists(combined_subdir):\n",
        "        os.makedirs(combined_subdir)\n",
        "\n",
        "# Function to copy files from source to destination\n",
        "def copy_files(source_path):\n",
        "    for dir_name in os.listdir(source_path):\n",
        "        source_dir_path = os.path.join(source_path, dir_name)\n",
        "        destination_dir_path = os.path.join(combined_path, dir_name)\n",
        "\n",
        "        if not os.path.exists(destination_dir_path):\n",
        "            os.makedirs(destination_dir_path)\n",
        "\n",
        "\n",
        "        for file_name in os.listdir(source_dir_path):\n",
        "            src_file_path = os.path.join(source_dir_path, file_name)\n",
        "            dst_file_path = os.path.join(destination_dir_path, file_name)\n",
        "\n",
        "            file_counter = 1\n",
        "            while os.path.exists(dst_file_path):\n",
        "                name, ext = os.path.splitext(file_name)\n",
        "                new_name = f\"{name}_{file_counter}{ext}\"\n",
        "                dst_file_path = os.path.join(destination_dir_path, new_name)\n",
        "                file_counter += 1\n",
        "\n",
        "            # Copy the file to the destination directory\n",
        "            shutil.copy(src_file_path, dst_file_path)\n",
        "\n",
        "copy_files(CCSN_path)\n",
        "copy_files(Howard_path)\n"
      ],
      "metadata": {
        "id": "7UGqlTfzJVE0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Recheck how many files there are in each cloud types"
      ],
      "metadata": {
        "id": "MGKM3qa4JRWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_path = '/content/combined_datasets'\n",
        "combined_dir = os.listdir(combined_path)\n",
        "\n",
        "for dir_name in combined_dir:\n",
        "    # Create the full path to the directory\n",
        "    dir_path = os.path.join(combined_path, dir_name)\n",
        "\n",
        "    # Get a list of files in the directory\n",
        "    files = os.listdir(dir_path)\n",
        "\n",
        "    # Count the number of files\n",
        "    num_files = len(files)\n",
        "\n",
        "    # Print the directory name and the number of files it contains\n",
        "    print(f\"{dir_name}: {num_files} files\")"
      ],
      "metadata": {
        "id": "ibP0oJADSDU-",
        "outputId": "a41ed9d0-0fc2-4f7a-ecec-098ac6f4fa83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ci: 194 files\n",
            "Ns: 293 files\n",
            "Sc: 340 files\n",
            "Cu: 297 files\n",
            "Cc: 236 files\n",
            "Ac: 254 files\n",
            "As: 252 files\n",
            "St: 339 files\n",
            "Cb: 317 files\n",
            "Cs: 187 files\n",
            "Ct: 155 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Processing**\n",
        "#### Import Dependancies and modules required"
      ],
      "metadata": {
        "id": "gYW46N579g2i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH5_wLSM9OSn"
      },
      "outputs": [],
      "source": [
        "import os #for creating path names and manipulating directories/files in an operating system\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1sYJp1N9OSn",
        "outputId": "d0fa32f9-7454-47bc-adcd-80322698a3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import os #for creating path names and manipulating directories/files in an operating system\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime #for tensorboard and logging\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Data Directory in Google Drive"
      ],
      "metadata": {
        "id": "XU6TAZGj_U5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CCSN Datasets"
      ],
      "metadata": {
        "id": "PblWm3m7AZfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Howard Datasets"
      ],
      "metadata": {
        "id": "HyCaEsVRAgAd"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}